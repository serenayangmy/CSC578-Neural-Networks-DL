<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-10-04 Sun 19:18 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>CSC 578 HW 3: Implementation of Neural Networks</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Fall 2020" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="../assignstyles.css" />
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>
<div id="content">
<h1 class="title">CSC 578 HW 3: Implementation of Neural Networks</h1>
<p>
Version 0.2b (with much credit to Prof. Tomuro), including here a link to <b><a href="hw3.zip">hw3.zip</a></b>, a zip file with all the other files in one place.
</p>

<p>
<b>Graded out of 10 points.</b>
</p>

<div id="outline-container-org0e817e5" class="outline-2">
<h2 id="org0e817e5">Introduction</h2>
<div class="outline-text-2" id="text-org0e817e5">
<p>
<a href="https://depaul.zoom.us/rec/share/-zonuJrt0IH8rDJpzLi8AEC7o1c_5q8YOOmoMYD6Ti2B6ak4-PJhVowd0Jwwp9pS.ALy2yPgsNCBpTScu">Video introduction to the project</a>
</p>

<p>
Your task in this assignment is to make some modifications to the NNDL book code "network.py" (in Chapter 1) and write a small application to use it.  The objective of the assignment is to help you strengthen your understanding of the concepts and mathematics of neural networks through implementation. 
</p>

<p>
The amount of code you write for this assignment won't be much.  However, understanding the code written by somebody else makes you learn not only the details of the code itself but the concepts implemented in the code.  This is a great exercise to develop your programming skills as well.
</p>
</div>

<div id="outline-container-org43c0710" class="outline-3">
<h3 id="org43c0710">Deliverables:</h3>
<div class="outline-text-3" id="text-org43c0710">
<p>
Submit these two things.  More instructions are found at the end of this page.
</p>

<ol class="org-ol">
<li>Code files</li>
<li>A documentation file</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org7ddcb86" class="outline-2">
<h2 id="org7ddcb86">Overview</h2>
<div class="outline-text-2" id="text-org7ddcb86">
<p>
The overall picture of your task is to:
</p>

<ol class="org-ol">
<li>Install and test a Jupyter notebook application running the (slightly modified) NNDL network code.</li>
<li>Make required modifications to the network code, and test it with a jupyter notebook.</li>
<li>Create a jupyter notebook application that uses your modified network code.</li>
</ol>
</div>
</div>


<div id="outline-container-org955395e" class="outline-2">
<h2 id="org955395e">Part 1: Initial tests of application notebook</h2>
<div class="outline-text-2" id="text-org955395e">
<p>
Download the network definition code <a href="./NN578_network.py">NN578_network.py</a>, the iris dataset: <a href="./iris.csv">iris.csv</a>, the saved network file: <a href="./iris-423.dat">iris-423.dat</a>, and the initial test application code (a Jupyter Notebook file): <a href="./578hw3-initial.ipynb">578hw3-initial.ipynb</a>. Run all cells in the initial application notebook.  Execution should succeed, and you should see the output for the last two cells like shown in <a href="578hw3-initial.html">this html file</a>, perhaps also with a deprecation warning.
</p>

<p>
If you are using Google CoLab, I recommend you create a new folder and put all necessary files there. Also here is the application notebook file <a href="./578hw3-initial-CoLab.ipynb">578hw3-initial-CoLab.ipynb</a> and <a href="./578hw3-initial-CoLab.ipynb - Colaboratory.pdf">a pdf file</a> of the output.
</p>
</div>
</div>


<div id="outline-container-orgc5741be" class="outline-2">
<h2 id="orgc5741be">Part 2: MODIFICATIONS to be made in the network code</h2>
<div class="outline-text-2" id="text-orgc5741be">
<p>
Here, you will extend the network definition code (<a href="NN578_network.py">NN578_network.py</a>) in several ways. (You may want to keep a copy of the original before you modify it.)
</p>
</div>

<div id="outline-container-orgaad0acf" class="outline-4">
<h4 id="orgaad0acf">IMPORTANT NOTES:</h4>
<div class="outline-text-4" id="text-orgaad0acf">
<ul class="org-ul">
<li>The network definition code (<a href="./NN578_network.py">NN578_network.py</a>) is pretty much the same as the book's original code 'network.py', but with <b>ONE IMPORTANT CHANGE</b> &#x2013; The target variable (<i>y</i>) of a dataset is assumed to be a <b>vector</b> (rather than a scalar), in particular in the form of so-called <b>'one-hot-vector'</b> representation, which is a list of all 0's with exactly one 1 for the target class.  For example, if there were four target classes in the given dataset (i.e., a "multiclass classification problem") and a particular instance's target class was three (the <i>third</i> one), the target would be encoded as [0, 0, 1, 0].  This encoding scheme is also called a <i>'categorical'</i> format. (There's also a minor tweak: It should work in python 3, but hasn't been tested in python2.)</li>

<li>Since a python script file is a static binding in Jupyter notebook (by an import statement), when you make changes in the network .py file (<code>NN578_network.py</code>), you must <b>re-start the kernel (runtime)</b> of the application (<code>578hw3.ipynb</code>) every time.</li>
</ul>
</div>
</div>

<div id="outline-container-orge606db4" class="outline-4">
<h4 id="orge606db4">Modifications:</h4>
<div class="outline-text-4" id="text-orge606db4">
<ol class="org-ol">
<li><p>
Edit the function <code>evaluate()</code> (which is called after an epoch is complete) so that, in addition to accuracy, it computes the Mean Squared Error (MSE), Cross-entropy and log-likelihood.  The function should return those five values (correctcount, accuracy, MSE, Cross-entropy and log-likelihood) in a list.
</p>

<p>
MSE is described in <a href="http://neuralnetworksanddeeplearning.com/chap1.html">NNDL 1</a> (Eq. (6)), and Cross-entropy is in <a href="http://neuralnetworksanddeeplearning.com/chap3.html">NNDL 3</a> (initially in Eq. (57), and more precisely in Eq. (63)).  Log likelihood (See * below) is in  <a href="http://neuralnetworksanddeeplearning.com/chap3.html">NNDL 3</a>  (Eq. (80)), but note that the formula is MISSING \(1/n\) in the beginning, which divides the sum by the number of instances in the dataset to give the average.
</p>

<p>
NOTE: Each cost function must return a <b>scalar</b> value, NOT an array.  You should ensure your code is indeed doing so correctly. (Hint: you could <code>assert</code> the <code>shape</code> of that variable's value.)
</p>

<ul class="org-ul">
<li>As a hint, for MSE and Cross-entropy, you can look at the two function classes (QuadraticCost and CrossEntropyCost) in another book code file <a href="./network2.py">network2.py</a> (the original version; to be modified in a homework later in the course).</li>

<li>(\(*\)) ANOTHER NOTE on <b>log likelihood</b>.  For this function, you have to pick out the activation value of a node for which the target <code>y</code> array has a one (represented by a so-called (binarized) 'one-hot vector').  Assuming you first get the index to the node (by calling <code>argmax</code> to the target <code>y</code>), then give the index to the output layer's activation array, you will have a problem &#x2013; Numpy's subscripting (with []) returns an array with one element, instead of a scalar, <b>because the activation values of a layer are stored in column vectors (rather than row vectors) in our code</b>.  Look at <a href="./Demo-NumpyIndex.html">this code snippet</a> for a demo of the behavior and a few solution ideas to get a scalar from the array.</li>
</ul>

<p>
Note that NO PRINTING takes place inside the function <code>evaluate()</code>.  It only <span class="underline">returns</span> the five values.
</p></li>

<li>Edit the <code>SGD()</code> function to include the <b>three</b> modifications described below:

<ul class="org-ul">
<li><p>
Call <code>evaluate()</code> for <code>training_data</code>, at the end of every epoch, and print the returned results in the format below.  <i>It should also</i> call <code>evaluate()</code> for <code>test_data</code> as well as the training set if it is passed in as an argument.  See the formatting example below.  Note that if <code>test_data</code> is not passed in, you omit the second line in the output for each epoch. 
</p>

<pre class="example" style="font-size: 70%" id="orgd45fdf6">
[Epoch 0] Training: MSE=aaaa, CE=xxxx, LL=yyyy, Correct: zzz/nnn, Acc: cccc
          Test:     MSE=bbbb, CE=xxxx, LL=yyyy, Correct: zzz/nnn, Acc: cccc
[Epoch 1] Training: MSE=aaaa, CE=xxxx, LL=yyyy, Correct: zzz/nnn, Acc: cccc
          Test:     MSE=bbbb, CE=xxxx, LL=yyyy, Correct: zzz/nnn, Acc: cccc
...
</pre>

<p>
Note that you <i>only</i> call <code>evaluate()</code> at the end of each epoch (i.e., after all minibatches are processed), for the training data, and for the test data if provided.
</p></li>

<li><p>
Collect the performance results returned from <code>evaluate()</code> for all epochs for <code>training_data</code> and <code>test_data</code> into individual lists, and return the two lists in a list.  Each list (for one dataset, train/test) will be like a <i>history</i>, since it collected the performance results for every epoch for the dataset (and it will be a list of lists, where each element is a list of size 5, and there are \(n\) such lists where \(n\) is the number of epochs).
</p>

<p>
Note that, if <code>test_data</code> was not provided, the collected list for <code>test_data</code> will be an empty list.
</p></li>

<li>Add a function parameter <code>stopaccuracy</code> with a <i>default value</i> of 1.0 (REQUIRED).  This parameter will be used to do <b>Early Stopping</b>, which stops looping through the epochs if the classification accuracy for the <i>training data</i> becomes &gt;= the <code>stopaccuracy</code> parameter.  Note: the value is assumed to be between 0 and 1.0 (where 1.0 means 100% accuracy).  You stop the loop at the end of the epoch loop, after <code>evaluate(test_data)</code> is called and its results are printed.</li>
</ul></li>

<li><p>
Edit the function <code>backprop()</code> so that the local variable <code>activations</code> is initially allocated with a structure which holds the activation value of ALL layers in the network from the start, rather than the current code which starts with just the input layer (by <code>activations = [x]</code>) and appends one layer at a time (by <code>activations.append(activation)</code>). 
</p>

<p>
For example, if the network size was [4, 20, 3], you create a list containing three Numpy arrays whose shapes are (4,1), (20,1) and (3,1) respectively.  Then during the forward-propagation, activation values of each layer are copied/assigned into the respective array.
</p></li>
</ol>
</div>
</div>

<div id="outline-container-org392e5c8" class="outline-3">
<h3 id="org392e5c8">Initial testing of modifications</h3>
<div class="outline-text-3" id="text-org392e5c8">
<p>
Test your modified network definition code with this next test application notebook: <a href="./578hw3-checktestset.ipynb">578hw3-checktestset.ipynb</a>.  Execution should succeed, and you should see the output for the last two cells as shown in <a href="./578hw3-checktestset.html">this html file</a>. (This was generated on IBM CognitiveLabs).
</p>
</div>
</div>
</div>


<div id="outline-container-org6f8a836" class="outline-2">
<h2 id="org6f8a836">Part 3: Further Application and Testing</h2>
<div class="outline-text-2" id="text-org6f8a836">
<p>
After passing the tests in the previous two steps, take the start-up file <a href="578hw3.ipynb">578hw3.ipynb</a> (<a href="578hw3.html">html)</a> and add code that implements the requirements below.  Then submit the notebook file, along with the network definition code.  Note that this is a Jupyter Notebook file; DO NOT change it to a python script file (.py). 
</p>

<p>
Your task is to add a collection of code snippets that do the following individual tasks in order (rather than an entire coherent program).
</p>

<ol class="org-ol">
<li>Further check your network definition code which includes the Modifications described above in Part 2, i.e., the changes to <code>evaluate()</code>, <code>SGD</code> (printing and return value), <code>backprop()</code> and <i>Early Stopping</i>.  Steps are:

<ul class="org-ul">
<li><p>
First, train the <code>net1</code> network (created in the initial steps of the "start-up file" from <code>iris-423.dat</code>) by training it on the iris data (<code>iris.csv</code>) by calling <code>SGD()</code> for a maximum of <b>100 epochs, minibatch_size=5, eta=0.5</b>.  No specific value should be passed in for <code>stopaccuracy</code> to take the default (1.0). 
</p>

<p>
Your results should match with the numbers shown in this file: <a href="Results-1.txt">Results-1.txt</a>. (This was generated on IBM CognitiveLabs.)
</p></li>

<li>Then, create another network by reloading the same saved network and train the network with the same three hyperparameter values AND additionally with <code>stopaccuracy=0.75</code>.  The output results will be the same from the previous run, but should stop after the training accuracy reached above 0.75.</li>
</ul></li>

<li>Check your code with a different, deeper network, in particular the <code>4-20-7-3</code> network.  Use this network file <a href="iris4-20-7-3.dat">iris4-20-7-3.dat</a>.

<ul class="org-ul">
<li>Create a new network by loading the saved <code>4-20-7-3</code> network, then train the network using the same hyperparameters from the last run <code>(epochs=100, minibatch_size=5, eta=0.5, stopaccuracy=0.75)</code>.  Your results should match with the numbers shown in this file &#x2013; <a href="Results-2.txt">Results-2.txt</a>.  (This was generated on IBM CognitiveLabs).</li>
</ul></li>

<li>Visualize the network learning by creating the following plots.  A few preliminary steps:

<ol class="org-ol">
<li><p>
First split the dataset randomly into 70% training and 30% test. 
</p>

<p>
There are many ways to do it, but a simple way is recommended (rather than using a function in packages such as sklearn).  For example, you first shuffle the instances in the original dataset, and take the first 70% as the training and the rest as the test.
</p></li>

<li><p>
Then create a new network (which has randomly initialized weights) of the size <code>[4,20,3]</code>.  You can create a new network by simply calling the constructor in this way:
</p>

<pre class="example" style="font-size: 80%" id="org9f96eca">
# Create a new network
net4 = network.Network([4,20,3])
</pre></li>

<li>Then train the network for 50 epochs with <code>eta = 0.1</code> and the <code>minibatch size = 5</code> (and take the default for <code>stopaccuracy</code>).  Save the results.</li>

<li><p>
Use the results to plot two types of plots as shown below.  Note that, since the initial weights are randomly assigned now, you may want to re-train several times until you see 'interesting' results. 
</p>

<p>
You can use any library to plot.  If you do not have experience plotting charts in Python, it's quite easy to do.  Here are some sites I recommend: <a href="http://www.datasciencemadesimple.com/line-plot-line-chart-in-python-legends/">(1)</a>: simple and good examples, <a href="https://matplotlib.org/users/pyplot_tutorial.html">(2)</a>: matplotlib tutorial, <a href="https://www.tensorflow.org/tutorials/keras/basic_text_classification">(3)</a> : Keras code example.
</p>

<p>
Note that you may need to convert Python lists to Numpy arrays, and reshape Numpy arrays (especially to ensure a row or column vector: [1,n] or [n,1]).  Figure out what works for your code.
</p>

<ol class="org-ol">
<li><p>
One plot that compares the error curves of the three cost functions for the training set.
</p>

<p>
Note the curves for CrossEntropy and LogLikelihood may not be smoothly decreasing &#x2013; it could well be the case because the backprop algorithm used MSE as the cost function to minimize error.  But at least it should be the case where LogLikelihood is always below CrossEntropy (and you should know why). (Click to see larger images of the plots.)
</p>


<div id="org6bf0106" class="figure">
<p><a href="hw2-temp1.png"><img src="hw2-temp1_small.png" alt="hw2-temp1_small.png" /></a> 
</p>
</div></li>

<li><p>
Three plots, one for each cost function, that shows the error for training vs. test (so that we can inspect for overfitting).
</p>

<p>
<a href="hw2-MSE.png"><img src="hw2-MSE_small.png" alt="hw2-MSE_small.png" /></a> <a href="hw2-CE.png"><img src="hw2-CE_small.png" alt="hw2-CE_small.png" /></a> <a href="hw2-LL.png"><img src="hw2-LL_small.png" alt="hw2-LL_small.png" /></a> 
</p></li>
</ol></li>
</ol></li>
</ol>
</div>
</div>

<div id="outline-container-orge55ab25" class="outline-2">
<h2 id="orge55ab25">Submission</h2>
<div class="outline-text-2" id="text-orge55ab25">
<ol class="org-ol">
<li>Two code files (your modified <code>NN578_network.py</code> and <code>578hw3.ipynb</code> files) <i>and</i> the <b>html version</b> of the latter Notebook file.

<ul class="org-ul">
<li>Be sure to add your <b>name, course/section number</b> and <b>the assignment name</b> at the top of <span class="underline">BOTH</span> code files.  Files without this information will be returned ungraded.</li>

<li>Don't forget the html file of the application code file.</li>
</ul></li>

<li>A documentation write-up. 
<ul class="org-ul">
<li><b>In pdf (only).</b></li>
<li>Minimum <b>1.5 pages</b> (i.e., one full page and a half of the second page is minimally filled).</li>
<li>Write as much as you can to demonstrate to me that you earned the points.  I consider terse answers insufficient. Full credit will not be given if information is missing or implied.  Create a presentable document. Don't make me work hard to find the information I asked for. (I've got a lot of these to read.)</li>
<li>Content should include, first, Your <b>name, course/section number</b> and the <b>assignment name</b> at the top of the file. And then in <b>separate, labeled sections</b>, reports on your success in the following tasks. Start each section with one of these three indicators: <b>Complete</b>, meaning you did the code and verified that it worked; <b>Not attempted</b>, meaning you didn't get there; or <b>Partial</b>, meaning that you have some code but it did not completely work, and explain why.
<ol class="org-ol">
<li>The "Initial testing" at the end of Part 2 (which checks for the test set, <a href="578hw3-checktestset.ipynb">578hw3-checktestset</a>).  State whether or not the output of your code matched the one shown in <a href="578hw3-checktestset.html">the html file</a>.</li>
<li>Modifications A and B matching  <a href="Results-1.txt">Results-1.txt</a>. If your results were different, describe the discrepancies and speculate where the discrepancies came from.</li>
<li>Testing with the deeper network, matching <a href="Results-2.txt">Results-2.txt</a> (explaining any discrepancies).</li>
<li>Present the visualization results (plots describe above).  Add your comments/analysis as well.</li>
<li>Your reaction and reflection on this assignment overall (e.g. difficulty level, challenges you had, future work).  <b>Describe in DETAIL.</b></li>
</ol></li>
</ul></li>
</ol>

<p>
DO NOT ZIP YOUR CODE OR WRITE UP. SUBMIT EACH FILE SEPARATELY.
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<hr/><p class="author">Fall 2020 (<a href="mailto:"></a>) 2020-10-04 Sun 19:18</p>
</div>
</body>
</html>
